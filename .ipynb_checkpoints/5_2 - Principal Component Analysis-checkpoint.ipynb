{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Principal Component Analysis\n",
    "\n",
    "In our last class we derived our first model *Linear Regression* by appealing to ideas from Linear Algebra (and Calculus). In the chapter before that we took some time to explore our data particularly looking at graphs and categorical variables trying to identify relations between predictors or relations between predictors and results. We also saw that in some cases adding additional variables helped us explain additional details of our model.\n",
    "\n",
    "You might, at this point, be a little bit unsettled. Particularly if your model is one with many features or has categorical features that with one-hot-encoding will become many features. How can we possibly identify all the relationships between features or identify the features that are most important in explaining our model. It is frankly, when we are thinking about a model with 81 features (before one-hot-encoding) a bit overwhelming.\n",
    "\n",
    "What we would like is a method of identifying the most important features in a model, the ones that will go the furthest to explaining our result value. Ideally this is a method that will work automatically without us having to make decisions. Luckily *Linear Algebra* again comes to the rescue with a result called *The Singular Value Decomposition* of a matrix which leads to the *Principal Component Analysis* of the predictors. \n",
    "\n",
    "We will take some time to describe this result here, for those of you who have had Linear Algebra, however at the end of the day this will be one more tool from scikitlearn that we will learn to use and if necessary you can think of it as a black-box (i.e. you put your matrix of predictors into it and it spits out the most important features). If you are interested in further background, I suggest the book *Applied Linear Algebra* by Gilbert Strang which is now available for free on the MIT Open Courseware Website.\n",
    "\n",
    "Now what we will actually get will be **linear combinations of the predictors** ordered by the the ones that explain the largest propotion of the variation between the samples."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Eigenvalue Decomposition of Square Matrix\n",
    "\n",
    "We begin our story by going back to what was probably one of the last things you learned about in your Linear Algebra class. Given a square matrix we can define eigenvalue and eigenvector pairs $(\\lambda, v)$ as solutions to the equation:\n",
    "\n",
    "$$ A v = \\lambda v $$\n",
    "\n",
    "Roughly these are vector directions in which $A$ actcs as a scalar. Putting the eigenvectors $v$ as columns of a matrix $Q$ we have:\n",
    "\n",
    "$$ A = Q D Q^{-1} $$\n",
    "\n",
    "where $Q$ is a matrix whose columnns are Eigenvectors; and $D$ is a diagonal matrix of the eigenvectors:\n",
    "\n",
    "$$ D = \\begin{pmatrix} \\lambda_0 & 0 & \\dots \\\\ 0 & \\lambda_1 & 0 & \\dots \\\\ & & \\ddots  \\\\ & & & \\lambda_n \\end{pmatrix} $$\n",
    "\n",
    "In the non-generic cases (i.e. special and rare cases) this decomposition is not possible, but generalizations of it, where $D$ is not diagonal, are. In the case that $A$ is symmetric ($A = A^T$) then this is further specialized to:\n",
    "\n",
    "$$ A = Q D Q^T $$\n",
    "\n",
    "where $Q Q^T = I$. A symmetric matrix also guaruntees that the eigenvalues are real.\n",
    "\n",
    "### Computing Eigenvalues\n",
    "\n",
    "You may have learned some techniques for computing eigenvalues. Usually you first learn that you can find them by solving the equation \n",
    "\n",
    "$$ \\mbox{det}( A - \\lambda I) = 0 $$\n",
    "\n",
    "It turns out that this possibly the worst way to compute them as it amounts to solving a polynomial of degree $n$. There are other \n",
    "techniques that are much more effecient especially if we want are approximate eigenvalues. These are what are implemented in Python's numpy module."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import numpy.linalg as la"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1 1 2]\n",
      " [1 3 1]\n",
      " [2 1 0]] (3, 3)\n"
     ]
    }
   ],
   "source": [
    "# Just to be explicit; let A be a square matrix\n",
    "\n",
    "A = np.array([ [1, 1, 2], [1, 3, 1], [2, 1, 0]])\n",
    "print(A, A.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-1.56884961  1.36444806  4.20440155] \n",
      " [[ 0.60350126 -0.6228405  -0.49785133]\n",
      " [ 0.04218655  0.64843974 -0.76009618]\n",
      " [-0.79624527 -0.43771637 -0.41760969]]\n"
     ]
    }
   ],
   "source": [
    "lam, Q = la.eig(A)\n",
    "print(lam, '\\n', v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 1.00000000e+00,  0.00000000e+00, -5.55111512e-17],\n",
       "       [ 0.00000000e+00,  1.00000000e+00, -2.22044605e-16],\n",
       "       [-5.55111512e-17, -2.22044605e-16,  1.00000000e+00]])"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Q @ Q.transpose()\n",
    "\n",
    "# note that we get the identity up to a machine 0."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Singular Value Decomposition\n",
    "\n",
    "Note though that for us, we are dealing with matrices $X$ that have many more rows than columns (or in the case of image problems many more columns than rows). Essentiallyh square matrices will not happen. However, noting what we learned with *Linear Regression* in the last chapter, it is maybe not a surprise that what we might want to consider is \n",
    "\n",
    "$$ X^T X \\qquad \\mbox{or} \\qquad X X^T $$\n",
    "\n",
    "If $X$ is $n$ by $m$ then $X^T X$ is square $m$ by $m$; while $X X^T$ is square $n$ by $n$. We could then compute their eigenvalue diagonalizations: \n",
    "\n",
    "$$ X^T X = V D_1 V^T $$ \n",
    "\n",
    "and \n",
    "\n",
    "$$ X X^T = U D_2 U^T $$\n",
    "\n",
    "where $V V^T = I_m $ and $ U U^T = I_n$ Note that the two identies are not equal and also that the diagonal matrices have different sizes.\n",
    "\n",
    "The singular value decomposition of $X$ is then:\n",
    "\n",
    "$$ X = U \\Sigma V^T $$\n",
    "\n",
    "The columns of $U$ and $V$ are left- and right-singular vectors and the $\\Sigma$ is a pseudo-diagonal matrix (it is $n$ by $m$ rather than square) of the singular values, which are positive real numbers:\n",
    "\n",
    "$$ \\Sigma = \\begin{pmatrix} s_0 & 0 & \\dots \\\\ 0 & s_1 & \\dots \\\\ \\vdots & \\vdots & \\ddots \\\\ 0 & \\dots & 0 \\end{pmatrix} $$\n",
    "\n",
    "$\\Sigma$ is unique, up to the order of the singular values, however the $U$ and $V$ are not unique. If we order $\\Sigma$ so that $s_0 > s_1 > \\dots > s_m $ then $V$ gives an operation that picks out of $X$ the most important contributions in order. I.e. transforming $X$ by the first $k$ columns of $V$ will give $k$ orthonormal linear combination of the columns of $X$ that produce column vectors that are the $k$ most important in explaining the variation of the entries of $X$. \n",
    "\n",
    "This is a little bit wishy-washy, so lets do a concrete example. \n",
    "\n",
    "### Iris Example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pa\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sepal length</th>\n",
       "      <th>sepal width</th>\n",
       "      <th>petal length</th>\n",
       "      <th>petal width</th>\n",
       "      <th>flower type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5.1</td>\n",
       "      <td>3.5</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4.9</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4.7</td>\n",
       "      <td>3.2</td>\n",
       "      <td>1.3</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4.6</td>\n",
       "      <td>3.1</td>\n",
       "      <td>1.5</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5.0</td>\n",
       "      <td>3.6</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   sepal length  sepal width  petal length  petal width  flower type\n",
       "0           5.1          3.5           1.4          0.2            0\n",
       "1           4.9          3.0           1.4          0.2            0\n",
       "2           4.7          3.2           1.3          0.2            0\n",
       "3           4.6          3.1           1.5          0.2            0\n",
       "4           5.0          3.6           1.4          0.2            0"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ird = pa.read_csv('Data Sets/iris.csv')\n",
    "ird.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is a collection of data giving the dimensions of the sepals and petals of three species of irises. The task is to predict the species from these values. It is relatively small for our class with only 150 samples and 5 features (4 predictors and 1 result) however it fullfills the important part of being largely non-square with more samples than predictors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(150, 5)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ird.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build a matrix of the predictors and results\n",
    "\n",
    "X = np.array(ird.iloc[:, 0:4])\n",
    "y = np.array(ird.iloc[:, 4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# We can check how the predictors do at classifying flower types by graphing individual pairs for example Sepal_Length and Sepal_Width\n",
    "\n",
    "plt.plot(X[y==0, 0], X[y==0, 1], 'r.')\n",
    "plt.plot(X[y==1, 0], X[y==1, 1], 'g.')\n",
    "plt.plot(X[y==2, 0], X[y==2, 1], 'b.');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On the one hand this is pretty good, and in fact it is clear that these two variables could easily be used to classify the flower type as 0 and not 0 with minimal error. However we have four variables and maybe by combining all 4 and taking the two best predictors we can do better."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((150, 150), (4,), (4, 4))"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "u, s, vt = la.svd(X, full_matrices=True)\n",
    "u.shape, s.shape, vt.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[95.95066751 17.72295328  3.46929666  1.87891236]\n"
     ]
    }
   ],
   "source": [
    "print(s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[95.95066751,  0.        ,  0.        ,  0.        ],\n",
       "       [ 0.        , 17.72295328,  0.        ,  0.        ],\n",
       "       [ 0.        ,  0.        ,  3.46929666,  0.        ],\n",
       "       [ 0.        ,  0.        ,  0.        ,  1.87891236],\n",
       "       [ 0.        ,  0.        ,  0.        ,  0.        ],\n",
       "       [ 0.        ,  0.        ,  0.        ,  0.        ],\n",
       "       [ 0.        ,  0.        ,  0.        ,  0.        ],\n",
       "       [ 0.        ,  0.        ,  0.        ,  0.        ],\n",
       "       [ 0.        ,  0.        ,  0.        ,  0.        ],\n",
       "       [ 0.        ,  0.        ,  0.        ,  0.        ]])"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# We can build sigma from s\n",
    "sigma = np.append(np.diag(s), np.zeros((150-4, 4)), axis=0 )\n",
    "sigma[:10, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 1.77635684e-15  1.02140518e-14  7.77156117e-15  4.38538095e-15]\n",
      " [ 0.00000000e+00  0.00000000e+00  6.21724894e-15  1.27675648e-15]\n",
      " [ 0.00000000e+00  1.77635684e-15  0.00000000e+00 -8.32667268e-16]\n",
      " [ 0.00000000e+00  1.33226763e-15  0.00000000e+00 -4.99600361e-16]\n",
      " [ 0.00000000e+00  1.77635684e-15  2.22044605e-16 -5.55111512e-17]\n",
      " [ 8.88178420e-16  2.66453526e-15  8.88178420e-16  2.22044605e-16]\n",
      " [-8.88178420e-16  1.33226763e-15  8.88178420e-16  2.77555756e-16]\n",
      " [ 8.88178420e-16  1.33226763e-15  4.44089210e-16 -5.55111512e-17]\n",
      " [ 0.00000000e+00  1.33226763e-15  0.00000000e+00 -5.55111512e-17]\n",
      " [ 0.00000000e+00  8.88178420e-16  0.00000000e+00 -2.77555756e-17]]\n"
     ]
    }
   ],
   "source": [
    "print( (u @ sigma @ vt - X)[0:10, :] )\n",
    "# Check that u, sigma, and vt reconstruct X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "v = vt.transpose()\n",
    "\n",
    "# The columns of v given, in descending order, the most important factors explaining the variations in X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Take the two most important factors and build a new X\n",
    "\n",
    "X2 = X @ v[:, 0:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# We can check how the predictors do at classifying flower types by graphing individual pairs for example Sepal_Length and Sepal_Width\n",
    "\n",
    "plt.plot(X2[y==0, 0], X2[y==0, 1], 'r.')\n",
    "plt.plot(X2[y==1, 0], X2[y==1, 1], 'g.')\n",
    "plt.plot(X2[y==2, 0], X2[y==2, 1], 'b.');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The size of the singular values actually identifies how important the new feature is. The more rapidly they decay the better the early features do at explaining the variations in the data.\n",
    "\n",
    "#### Principal Component Analysis\n",
    "\n",
    "Scikitlearn contains a variation on this method called Principal Component Analysis that does the computation here, but also normalizes the results in a way that is better suited for data analysis and varies the routines and approximations to run as effeciently as possible on the data you use. It also has some attached functions that can be used to illustrate how well the method has worked.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "pca = PCA(n_components=2) # Use PCA to identify the two most important components\n",
    "\n",
    "# component here means a linear combination of the features\n",
    "\n",
    "Xpca = pca.fit_transform(X);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# We can check how the predictors do at classifying flower types by graphing individual pairs for example Sepal_Length and Sepal_Width\n",
    "\n",
    "plt.plot(Xpca[y==0, 0], Xpca[y==0, 1], 'r.')\n",
    "plt.plot(Xpca[y==1, 0], Xpca[y==1, 1], 'g.')\n",
    "plt.plot(Xpca[y==2, 0], Xpca[y==2, 1], 'b.');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.92461621 0.05301557]\n"
     ]
    }
   ],
   "source": [
    "# The explained variance quantifies the propotion of the variation in the values of X that have been explained by each component\n",
    "\n",
    "print(pca.explained_variance_ratio_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that PCA is our first example of an unsupervised learning method (it works independently of the result values and rather tries to organize the predictors)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Warning\n",
    "\n",
    "It is worth ending with a warning. PCA does not always lead us to a model with good results. You should think of it as one more tool in our toolbox. It is worth using it to try and identify the important characteristics, but\n",
    "\n",
    "1. It is not the only method for doing that; and\n",
    "2. It will not always produce an improved model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Id</th>\n",
       "      <th>MSSubClass</th>\n",
       "      <th>MSZoning</th>\n",
       "      <th>LotFrontage</th>\n",
       "      <th>LotArea</th>\n",
       "      <th>Street</th>\n",
       "      <th>Alley</th>\n",
       "      <th>LotShape</th>\n",
       "      <th>LandContour</th>\n",
       "      <th>Utilities</th>\n",
       "      <th>...</th>\n",
       "      <th>PoolArea</th>\n",
       "      <th>PoolQC</th>\n",
       "      <th>Fence</th>\n",
       "      <th>MiscFeature</th>\n",
       "      <th>MiscVal</th>\n",
       "      <th>MoSold</th>\n",
       "      <th>YrSold</th>\n",
       "      <th>SaleType</th>\n",
       "      <th>SaleCondition</th>\n",
       "      <th>SalePrice</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>60</td>\n",
       "      <td>RL</td>\n",
       "      <td>65.0</td>\n",
       "      <td>8450</td>\n",
       "      <td>Pave</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Reg</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2008</td>\n",
       "      <td>WD</td>\n",
       "      <td>Normal</td>\n",
       "      <td>208500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>20</td>\n",
       "      <td>RL</td>\n",
       "      <td>80.0</td>\n",
       "      <td>9600</td>\n",
       "      <td>Pave</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Reg</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>2007</td>\n",
       "      <td>WD</td>\n",
       "      <td>Normal</td>\n",
       "      <td>181500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>60</td>\n",
       "      <td>RL</td>\n",
       "      <td>68.0</td>\n",
       "      <td>11250</td>\n",
       "      <td>Pave</td>\n",
       "      <td>NaN</td>\n",
       "      <td>IR1</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "      <td>2008</td>\n",
       "      <td>WD</td>\n",
       "      <td>Normal</td>\n",
       "      <td>223500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>70</td>\n",
       "      <td>RL</td>\n",
       "      <td>60.0</td>\n",
       "      <td>9550</td>\n",
       "      <td>Pave</td>\n",
       "      <td>NaN</td>\n",
       "      <td>IR1</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2006</td>\n",
       "      <td>WD</td>\n",
       "      <td>Abnorml</td>\n",
       "      <td>140000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>60</td>\n",
       "      <td>RL</td>\n",
       "      <td>84.0</td>\n",
       "      <td>14260</td>\n",
       "      <td>Pave</td>\n",
       "      <td>NaN</td>\n",
       "      <td>IR1</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>12</td>\n",
       "      <td>2008</td>\n",
       "      <td>WD</td>\n",
       "      <td>Normal</td>\n",
       "      <td>250000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows  81 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Id  MSSubClass MSZoning  LotFrontage  LotArea Street Alley LotShape  \\\n",
       "0   1          60       RL         65.0     8450   Pave   NaN      Reg   \n",
       "1   2          20       RL         80.0     9600   Pave   NaN      Reg   \n",
       "2   3          60       RL         68.0    11250   Pave   NaN      IR1   \n",
       "3   4          70       RL         60.0     9550   Pave   NaN      IR1   \n",
       "4   5          60       RL         84.0    14260   Pave   NaN      IR1   \n",
       "\n",
       "  LandContour Utilities  ... PoolArea PoolQC Fence MiscFeature MiscVal MoSold  \\\n",
       "0         Lvl    AllPub  ...        0    NaN   NaN         NaN       0      2   \n",
       "1         Lvl    AllPub  ...        0    NaN   NaN         NaN       0      5   \n",
       "2         Lvl    AllPub  ...        0    NaN   NaN         NaN       0      9   \n",
       "3         Lvl    AllPub  ...        0    NaN   NaN         NaN       0      2   \n",
       "4         Lvl    AllPub  ...        0    NaN   NaN         NaN       0     12   \n",
       "\n",
       "  YrSold  SaleType  SaleCondition  SalePrice  \n",
       "0   2008        WD         Normal     208500  \n",
       "1   2007        WD         Normal     181500  \n",
       "2   2008        WD         Normal     223500  \n",
       "3   2006        WD        Abnorml     140000  \n",
       "4   2008        WD         Normal     250000  \n",
       "\n",
       "[5 rows x 81 columns]"
      ]
     },
     "execution_count": 151,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Consider the following dataset about homes that sold in a city in Iowa\n",
    "\n",
    "hd = pa.read_csv('Data Sets/house-prices/train.csv')\n",
    "\n",
    "hd.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [],
   "source": [
    "def onehot(df, feature):\n",
    "    '''A function to do one-hot-encoding of a feature from a dataframe. df = dataframe'''\n",
    "\n",
    "    v = list(set(df[feature])) # Make an iterable of the unique values for the feature\n",
    "    \n",
    "    for c in df.index: # cycle through the samples\n",
    "        t = df.loc[c, feature]\n",
    "        \n",
    "        for test in v:\n",
    "            if pa.isna(test):  # nan values are sort of a problem and have to be handled separately\n",
    "                if pa.isna(t):\n",
    "                    df.loc[c, '{}_nan'.format(feature)] = 1\n",
    "                else:\n",
    "                    df.loc[c, '{}_nan'.format(feature)] = 0\n",
    "            else:\n",
    "                if t == test:\n",
    "                    df.loc[c, '{}_{}'.format(feature, test)] = 1  # Makes a new feature with name feature_value\n",
    "                                                              # and codes it as a 1 if that was the value\n",
    "                else:\n",
    "                    df.loc[c, '{}_{}'.format(feature, test)] = 0  # and 0 otherwise\n",
    "            \n",
    "    return df.drop(feature, axis=1) # returns a dataframe with the encoded feature removed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>LotArea</th>\n",
       "      <th>1stFlrSF</th>\n",
       "      <th>2ndFlrSF</th>\n",
       "      <th>BedroomAbvGr</th>\n",
       "      <th>FullBath</th>\n",
       "      <th>HalfBath</th>\n",
       "      <th>SalePrice</th>\n",
       "      <th>Alley_nan</th>\n",
       "      <th>Alley_Pave</th>\n",
       "      <th>Alley_Grvl</th>\n",
       "      <th>ExterQual_Fa</th>\n",
       "      <th>ExterQual_Gd</th>\n",
       "      <th>ExterQual_TA</th>\n",
       "      <th>ExterQual_Ex</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>8450</td>\n",
       "      <td>856</td>\n",
       "      <td>854</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>208500</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>9600</td>\n",
       "      <td>1262</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>181500</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>11250</td>\n",
       "      <td>920</td>\n",
       "      <td>866</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>223500</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>9550</td>\n",
       "      <td>961</td>\n",
       "      <td>756</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>140000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>14260</td>\n",
       "      <td>1145</td>\n",
       "      <td>1053</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>250000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   LotArea  1stFlrSF  2ndFlrSF  BedroomAbvGr  FullBath  HalfBath  SalePrice  \\\n",
       "0     8450       856       854             3         2         1     208500   \n",
       "1     9600      1262         0             3         2         0     181500   \n",
       "2    11250       920       866             3         2         1     223500   \n",
       "3     9550       961       756             3         1         0     140000   \n",
       "4    14260      1145      1053             4         2         1     250000   \n",
       "\n",
       "   Alley_nan  Alley_Pave  Alley_Grvl  ExterQual_Fa  ExterQual_Gd  \\\n",
       "0        1.0         0.0         0.0           0.0           1.0   \n",
       "1        1.0         0.0         0.0           0.0           0.0   \n",
       "2        1.0         0.0         0.0           0.0           1.0   \n",
       "3        1.0         0.0         0.0           0.0           0.0   \n",
       "4        1.0         0.0         0.0           0.0           1.0   \n",
       "\n",
       "   ExterQual_TA  ExterQual_Ex  \n",
       "0           0.0           0.0  \n",
       "1           1.0           0.0  \n",
       "2           0.0           0.0  \n",
       "3           1.0           0.0  \n",
       "4           0.0           0.0  "
      ]
     },
     "execution_count": 204,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hd2 = onehot(hd, 'Alley')\n",
    "hd3 = onehot(hd2, 'ExterQual')\n",
    "keep = ['LotArea', '1stFlrSF', '2ndFlrSF', 'BedroomAbvGr', 'FullBath', 'HalfBath', 'SalePrice', \n",
    "      'Alley_nan', 'Alley_Pave', 'Alley_Grvl', 'ExterQual_Fa', 'ExterQual_Gd', 'ExterQual_TA', 'ExterQual_Ex']\n",
    "hd4 = hd3.loc[:, keep]\n",
    "hd4.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert them to Numpy Arrays X for predictors and y for result\n",
    "\n",
    "keep.remove('SalePrice')\n",
    "X = np.array(hd4.loc[:, keep])\n",
    "y = np.array(hd4.loc[:, 'SalePrice'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "metadata": {},
   "outputs": [],
   "source": [
    "for k in range(X.shape[1]):\n",
    "    X[:, k] = (X[:, k] - min(X[:, k]))/(max(X[:, k]) - min(X[:, k]))\n",
    "    \n",
    "# It is helpful here to normalize the variables before running the PCA computation (though you will see not that helpful)\n",
    "# Normalization, similar to PCA is another tool for our toolbox. It rescales the variables being used to be distributed from [0, 1]\n",
    "# You called also use normalizations based on mean and standard deviation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy.random as rn\n",
    "from sklearn.linear_model import LinearRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We shuffle the data using a random permutation\n",
    "\n",
    "n = X.shape[0]\n",
    "test = int(0.20*n)            # We will use a test set made up of 20% of the data from our sample\n",
    "perm = rn.permutation(n)   \n",
    "X = X[perm]\n",
    "y = y[perm]\n",
    "X_test = X[:test]       # Then create the test\n",
    "y_test = y[:test]\n",
    "X_train = X[test:]     # and train sets\n",
    "y_train = y[test:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "metadata": {},
   "outputs": [],
   "source": [
    "pca = PCA(n_components = 3)\n",
    "Xpca_train = pca.fit_transform(X_train)\n",
    "Xpca_test = pca.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.56820063, 0.11722931, 0.1083351 ])"
      ]
     },
     "execution_count": 210,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pca.explained_variance_ratio_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.4043562498472529, 0.33992170302433533)"
      ]
     },
     "execution_count": 211,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reg = LinearRegression().fit(Xpca_train, y_train)\n",
    "\n",
    "reg.score(Xpca_train, y_train), reg.score(Xpca_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Things get better for a bit as your increase the number of components to use, note that the explained variance of the components is not going to zero very fast. Eventually though the problem bottoms out. You end up with a best possible training fit but with diminishing returns on the testing fit."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pca_regression(k):\n",
    "    pca = PCA(n_components = k)\n",
    "    Xpca_train = pca.fit_transform(X_train)\n",
    "    Xpca_test = pca.transform(X_test)\n",
    "    \n",
    "    reg = LinearRegression().fit(Xpca_train, y_train)\n",
    "\n",
    "    return reg.score(Xpca_train, y_train), reg.score(Xpca_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0.33907636788290957, 0.24693830890984603)\n",
      "(0.33909396324789387, 0.24681597534636046)\n",
      "(0.40435624984725244, 0.339921703024335)\n",
      "(0.5451534405797952, 0.47787299935918426)\n",
      "(0.5713792429168281, 0.5340072007167783)\n",
      "(0.5714342254209799, 0.5344040805547052)\n",
      "(0.6295255172093048, 0.5621871976868345)\n",
      "(0.629542270297095, 0.56172123813227)\n",
      "(0.63624218218301, 0.5866002853083151)\n",
      "(0.742585769403826, 0.6858189443586089)\n",
      "(0.7428250663550455, 0.6849315419525175)\n",
      "(0.7428250663550455, 0.6849315419525175)\n"
     ]
    }
   ],
   "source": [
    "# Computing the Training and Testing R2 values as the number of PCA components is increased \n",
    "\n",
    "for k in range(1, 13):\n",
    "        print(pca_regression(k))\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
